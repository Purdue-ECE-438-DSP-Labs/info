{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>\n",
    "    ECE 438 - Laboratory 7a<br/>\n",
    "    Discrete-Time Random Process (Week 1)<br/>\n",
    "    <small>Last updated on March 1, 2022</small>\n",
    "</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the plot is displayed in this notebook\n",
    "%matplotlib inline\n",
    "# specify the size of the plot\n",
    "plt.rcParams['figure.figsize'] = (16, 6)\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:salmon;\"><left>1. Introduction</left></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the phenomena that occur in nature have uncertainty and are best characterized statistically as random processes. For example, the thermal noise in electronic circuits, radar detection, and games of chance are best modeled and analyzed in terms of statistical averages.\n",
    "\n",
    "This lab will cover some basic methods of analyzing random processes. [Section 2](#2.-Random-Variables) reviews some basic definitions and terminology associated with random variables, observations, and estimation. [Section 3](#3.-Estimating-the-Cumulative-Distribution-Function) investigates a common estimate of the cumulative distribution function. [Section 4](#4.-Generating-Samples-from-a-Given-Distribution) discusses the problem of transforming a random variable so that it has a given distribution, and lastly, [Section 5](#5.-Estimating-the-Probability-Density-Function) illustrates how the *histogram may* be used to estimate the probability density function.\n",
    "\n",
    "Note that this lab assumes an introductory background in probability theory. Some review is provided, but it is unfeasible to develop the theory in detail. A secondary reference such as [1] is strongly encouraged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:salmon;\"><left>2. Random Variables</left></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section contains an abbreviated review of some of the basic definitions associated with random variables. Then we will discuss the concept of an *observation* of a random event, and introduce the notion of an *estimator*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:salmon;\"><left>2.1 Basic Definitions</left></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **random variable** is a function that maps a set of possible outcomes of a random experiment into a set of real numbers. The probability of an event can then be interpreted as the probability that the random variable will take on a value in a corresponding subset of the real line. This allows a fully numerical approach to modeling probabilistic behavior.\n",
    "\n",
    "A very important function used to characterize a random variable is the **cumulative distribution function (CDF)**, defined as\n",
    "\n",
    "\\begin{equation}\n",
    "    F_X(x)=\\mathbb{P}(X\\leq x)\\quad x\\in(-\\infty,\\infty)\\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "Here, $X$ is the random variable, and $F_X(x)$ is the probability that $X$ will take on a value in the interval $(−\\infty, x]$. It is important to realize that $x$ is simply a dummy variable for the function $F_X(x)$, and is therefore not random at all.\n",
    "\n",
    "The derivative of the cumulative distribution function, if it exists, is known as the **probability density function**, denoted as $f_X(x)$. By the fundamental theorem of calculus, the probability density has the following property:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\int_{t_0}^{t_1}f_X(x)dx&=F_X(t_1)-F_X(t_0)\\tag{2}\\\\\n",
    "    &=\\mathbb{P}(t_0<X\\leq t_1)\n",
    "\\end{align*}\n",
    "\n",
    "Since the probability that $X$ lies in the interval $(−\\infty,\\infty)$ equals one, the entire area under the density function must also equal one.\n",
    "\n",
    "**Expectations** are fundamental quantities associated with random variables. The expected value of some function of $X$, call it $g(X)$, is defined by the following.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbb{E}[g(X)]&=\\int_{-\\infty}^{\\infty}g(x)f_X(x)dx\\quad\\text{(for $X$ continuous)}\\\\\n",
    "    \\mathbb{E}[g(X)]&=\\sum_{x=-\\infty}^{\\infty}g(x)\\mathbb{P}(X=x)\\quad\\text{(for $X$ discrete)}\n",
    "\\end{align*}\n",
    "\n",
    "Note that expected value of $g(X)$ is a deterministic number. Note also that due to the properties of integration, expectation is a linear operator.\n",
    "\n",
    "The two most common expectations are the mean $\\mu_X$ and variance $\\sigma_X^2$, defined by\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mu_X&=\\mathbb{E}[X]=\\int_{-\\infty}^{\\infty}xf_X(x)dx\\tag{3}\\\\\n",
    "    \\sigma_X^2&=\\mathbb{E}\\left[(X-\\mu_X)^2\\right]=\\int_{-\\infty}^{\\infty}(x-\\mu_X)^2f_X(x)dx\\tag{4}\n",
    "\\end{align*}\n",
    "\n",
    "A very important type of random variable is the **Gaussian or normal random variable**. A Gaussian random variable has a density function of the following form:\n",
    "\n",
    "\\begin{equation}\n",
    "    f_X(x)=\\frac{1}{\\sqrt{2\\pi\\sigma_X^2}}\\text{exp}\\left\\{-\\frac{1}{2\\sigma_X^2}(x-\\mu_X)^2\\right\\}\\tag{5}\n",
    "\\end{equation}\n",
    "\n",
    "Note that a Gaussian random variable is completely characterized by its mean and variance. This is not necessarily the case for other types of distributions. Sometimes, the notation $X\\sim \\mathcal{N}(\\mu,\\sigma^2)$ is used to identify $X$ as being Gaussian with mean $\\mu$ and variance $\\sigma^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:salmon;\"><left>2.2 Samples of a Random Variable</left></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose some random experiment may be characterized by a random variable $X$ whose distribution is unknown. For example, suppose we are measuring a deterministic quantity $v$, but our measurement is subject to a random measurement error $\\varepsilon$. We can then characterize the observed value, $X$, as a random variable, $X = v + \\varepsilon$.\n",
    "\n",
    "If the distribution of $X$ does not change over time, we may gain further insight into $X$ by making several independent observations ${X_1,X_2,\\dots,X_N}$. These observations $X_i$, also known as **samples**, will be independent random variables and have the same distribution $F_X(x)$. In this situation, the $X_i$’s are referred to as *i.i.d.*, for *independent and identically distributed*. We also sometimes refer to ${X_1,X_2,\\dots,X_N}$ collectively as a sample, or observation, of size $N$.\n",
    "\n",
    "Suppose we want to use our observation ${X_1,X_2,\\dots,X_N}$ to estimate the mean and variance of $X$. Two estimators which should already be familiar to you are the **sample mean** and **sample variance** defined by\n",
    "\n",
    "\\begin{align*}\n",
    "    \\hat{\\mu}_X&=\\frac{1}{N}\\sum_{i=1}^{N}X_i\\tag{6}\\\\\n",
    "    \\hat{\\sigma}_X^2&=\\frac{1}{N-1}\\sum_{i=1}^N(X_i-\\hat{\\mu}_X)^2\\tag{7}\n",
    "\\end{align*}\n",
    "\n",
    "It is important to realize that these sample estimates are functions of random variables, and are therefore themselves random variables. Therefore we can also talk about the statistical properties of the estimators. For example, we can compute the mean and variance of the sample mean $\\hat{\\mu}_X$.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbb{E}[\\hat{\\mu}_X]&=\\mathbb{E}\\left[\\frac{1}{N}\\sum_{i=1}^NX_i\\right]=\\frac{1}{N}\\sum_{i=1}^N\\mathbb{E}[X_i]=\\mu_X\\tag{8}\\\\\n",
    "    \\text{Var}[\\hat{\\mu}_X]&=\\text{Var}\\left[\\frac{1}{N}\\sum_{i=1}^NX_i\\right]=\\frac{1}{N^2}\\text{Var}\\left[\\sum_{i=1}^NX_i\\right]\\\\\n",
    "    &=\\frac{1}{N^2}\\sum_{i=1}^N\\text{Var}[X_i]\\\\\n",
    "    &=\\frac{\\sigma_X^2}{N}\\tag{9}\n",
    "\\end{align*}\n",
    "\n",
    "In both (8) and (9) we have used the i.i.d. assumption. We can also show that $\\mathbb{E}[\\hat{\\sigma}_X^2]=\\sigma_X^2$.\n",
    "\n",
    "An estimate $\\hat{a}$ for some parameter a which has the property $\\mathbb{E}[\\hat{a}] = a$ is said to be an **unbiased** estimate. An estimator such that $\\text{Var}[\\hat{a}]\\rightarrow0$ as $N\\rightarrow\\infty$ is said to be **consistent**. These two properties are highly desirable because they imply that if a large number of samples are used the estimate will be close to the true parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red;\"><left>Exercise 2.1</left></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose $X$ is a Gaussian random variable with mean $0$ and variance $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Use the Python function [`np.random.normal(loc=0, scale=1, size=1000)`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html) to generate $1000$ samples of $X$, denoted as $X_1,X_2,\\dots,X_{1000}$. We will assume our generated samples are *i.i.d.*.**\n",
    "\n",
    "**Note:** `loc` is the mean (“centre”) of the distribution, while `scale` is the **standard deviation** (spread or “width”) of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Plot them using the function ```plt.plot()```.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Write Python functions to compute the sample mean and sample variance of equations (6) and (7) without using the predefined `mean()`, `variance()`, `np.mean()` and `np.var()` functions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_mean(X):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ---\n",
    "    X: the samples of the random variable\n",
    "    \n",
    "    Returns\n",
    "    ---\n",
    "    mean_X: the sample mean of the random variable\n",
    "    \"\"\"\n",
    "    mean_X = None\n",
    "    return mean_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_var(X):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ---\n",
    "    X: the samples of the random variable\n",
    "    \n",
    "    Returns:\n",
    "    ---\n",
    "    var_X: the sample variance of the random variable\n",
    "    \"\"\"\n",
    "    var_X = None\n",
    "    return var_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Use these functions to compute the sample mean and sample variance of the samples you just generated.**\n",
    "\n",
    "**Hint:** the following functions may be useful: ```np.sum()```and ```np.square```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:salmon;\"><left>2.3 Linear Transformation of a Random Variable</left></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear transformation of a random variable $X$ has the following form\n",
    "\n",
    "\\begin{equation}\n",
    "    Y=aX+b\\tag{10}\n",
    "\\end{equation}\n",
    "\n",
    "where $a$ and $b$ are real numbers, and $a\\neq0$. A very important property of linear transformations is that they are *distribution-preserving*, meaning that $Y$ will be random variable with a distribution of the same form as $X$. For example, in (10), if $X$ is Gaussian then $Y$ will also be Gaussian, but not necessarily with the same mean and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red;\"><left>Exercise 2.2</left></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Using the linearity property of expectation, find the mean $\\mu_Y$ and variance $\\sigma_Y^2$ of $Y$ in terms of $a,b,\\mu_X$ and $\\sigma_X^2$. Show your derivation in detail.**\n",
    "\n",
    "**Hint:** First find the mean, then substitute the result when finding the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Consider a linear transformation of a Gaussian random variable $X$ with mean $0$ and variance $1$. Calculate the constants $a$ and $b$ which make the mean and the variance of $Y$ $3$ and $9$, respectively.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Use equation (5) to find the probability density function (PDF) for $Y$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Generate $1000$ samples of $X$, and then calculate $1000$ samples of $Y$ by applying the linear transformation in equation (10), using the $a$ and $b$ that you just determined.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Plot the resulting samples of $Y$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Use your functions to calculate the sample mean and sample variance of the samples of $Y$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:salmon;\"><left>3. Estimating the Cumulative Distribution Function</left></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to model some phenomenon as a random variable $X$ with distribution $F_X(x)$. How can we assess whether or not this is an accurate model? One method would be to make many observations and estimate the distribution function based on the observed values. If the distribution estimate is “close” to our proposed model $F_X(x)$, we have evidence that our model is a good characterization of the phenomenon. This section will introduce a common estimate of the cumulative distribution function.\n",
    "\n",
    "Given a set of i.i.d. random variables ${X_1,X_2,\\dots,X_N}$ with CDF $F_X(x)$, the *empirical* cumulative distribution function $\\hat{F}_X(x)$ is defined as the following.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\hat{F}_X(x)&=\\frac{1}{N}\\sum_{i=1}^N\\mathbb{1}_{X_i\\leq x}\\tag{11}\\\\\n",
    "    \\mathbb{1}_{X_i\\leq x}&=\\begin{cases}1,\\quad&\\text{if }X_i\\leq x\\\\0,\\quad&\\text{otherwise}\\end{cases}\\tag{12}\n",
    "\\end{align*}\n",
    "\n",
    "In words, $\\hat{F}_X(x)$ is the fraction of the $X_i$’s which are less than or equal to $x$.\n",
    "\n",
    "To get insight into the estimate $\\hat{F}_X(x)$, let’s compute its mean and variance. To do so, it is easiest to first define $N_x$ as the number of $X_i$’s which are less than or equal to $x$.\n",
    "\n",
    "\\begin{align*}\n",
    "    N_x=\\sum_{i=1}^N\\mathbb{1}_{X_i\\leq x}=N\\hat{F}_X(x)\\tag{13}\n",
    "\\end{align*}\n",
    "\n",
    "Notice that $\\mathbb{P}(X_i\\leq x)=F_X(x)$, so\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbb{P}(\\mathbb{1}_{X_i\\leq x}=1)&=F_X(x)\\\\\n",
    "    \\mathbb{P}(\\mathbb{1}_{X_i\\leq x}=0)&=1-F_X(x)\n",
    "\\end{align*}\n",
    "\n",
    "Now we can compute the mean of $\\hat{F}_X(x)$ as follows,\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbb{E}\\left[\\hat{F}_X(x)\\right]&=\\frac{1}{N}\\mathbb{E}[N_x]\\\\\n",
    "    &=\\frac{1}{N}\\sum_{i=1}^N\\mathbb{E}\\left[\\mathbb{1}_{X_i\\leq x}\\right]\\\\\n",
    "    &=\\frac{1}{N}N\\mathbb{E}\\left[\\mathbb{1}_{X_i\\leq x}\\right]\\\\\n",
    "    &=0\\cdot\\mathbb{P}\\left(\\mathbb{1}_{X_i\\leq x}=0\\right)+1\\cdot\\mathbb{P}\\left(\\mathbb{1}_{X_i\\leq x}=1\\right)\\\\\n",
    "    &=F_X(x)\n",
    "\\end{align*}\n",
    "\n",
    "This shows that $\\hat{F}_X(x)$ is an unbiased estimate of $F_X(x)$. By a similar approach, we can show that\n",
    "\n",
    "\\begin{align*}\n",
    "    \\text{Var}\\left[\\hat{F}_X(x)\\right]=\\frac{1}{N}F_X(x)(1-F_X(x))\n",
    "\\end{align*}\n",
    "\n",
    "Therefore, the empirical CDF $\\hat{F}_X(x)$ is both an unbiased and consistent estimate of the true CDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red;\"><left>Exercise 3.1</left></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Write a function to compute the empirical CDF $\\hat{F}_X(t)$ from the sample vector $X$ at the points specified in the vector $t$.**\n",
    "\n",
    "**Hint:** The expression ```np.sum(X <= s)``` will return the number of elements in the vector ```X``` which are less than or equal to ```s```.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empcdf(X,t):\n",
    "    \"\"\"\n",
    "    Parameter\n",
    "    ---\n",
    "    X: the samples of the random variable\n",
    "    t: the samples of time\n",
    "    \n",
    "    Return\n",
    "    ---\n",
    "    F: the empirical CDF\n",
    "    \"\"\"\n",
    "    return F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. For $N=20$ and $N=200$,**\n",
    "  * **Generate a sample of $\\text{Uniform}[0, 1]$ random variables using the function `X = np.random.uniform(0, 1, N)`.**\n",
    "  * **Plot the CDF estimate in the range ```t = np.linspace(-1, 2, 2000)```, and superimpose the true distribution for a $\\text{Uniform}[0, 1]$ random variable.**\n",
    "  \n",
    "**Note:** make sure the figures for $N=20$ and $N=200$ are plotted in separate cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:salmon;\"><left>4. Generating Samples from a Given Distribution</left></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is oftentimes necessary to generate samples from a particular distribution. For example, we might want to run simulations to test how an algorithm performs on noisy inputs. In this section we will address the problem of generating random numbers from a given distribution $F_X(x)$.\n",
    "\n",
    "Suppose we have a continuous random variable $X$ with distribution $F_X(x)$, and we form the new random variable $Y=F_X(X)$. In other words $Y$ is a function of $X$, and the particular function is the CDF of the random variable $X$.\n",
    "\n",
    "\\begin{align*}\n",
    "    X\\rightarrow F_X(\\cdot)\\rightarrow Y\\tag{14}\n",
    "\\end{align*}\n",
    "\n",
    "How is $Y$ distributed? First notice that $F_X(\\cdot)$ is a probability, so that $Y$ can only take values in the interval $[0,1]$.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbb{P}(Y\\leq y)=\\begin{cases}0,\\quad&\\text{for }y<0\\\\1,\\quad&\\text{for }y>1\\end{cases}\\tag{15}\n",
    "\\end{align*}\n",
    "\n",
    "Since $F_X(x)$ is a monotonically increasing function of $x$, the event ${Y\\leq y}$ is equivalent to ${X\\leq x}$ if we define $y=F_X(x)$. This implies that for $0\\leq y \\leq 1$,\n",
    "\n",
    "\\begin{align*}\n",
    "    F_Y(y)&=\\mathbb{P}(Y\\leq y)\\\\\n",
    "    &=\\mathbb{P}(F_X(X)\\leq F_X(x))\\\\\n",
    "    &=\\mathbb{P}(X\\leq x)\\quad\\text{(monotonicity)}\\\\\n",
    "    &=F_X(x)\\\\\n",
    "    &=y\n",
    "\\end{align*}\n",
    "\n",
    "Therefore, $Y$ is uniformly distributed on the interval $[0,1]$.\n",
    "\n",
    "Conversely, if $F_X(\\cdot)$ is a one-to-one function, we may use the inverse transformation $F_X^{-1}(U)$ to transform a Uniform[0,1] random variable $U$ to a random variable with distribution $F_X(\\cdot)$.\n",
    "\n",
    "\\begin{align*}\n",
    "    U\\rightarrow F_X^{-1}(\\cdot)\\rightarrow X\\tag{16}\n",
    "\\end{align*}\n",
    "\n",
    "Note that combining these results allows use to transform any continuous random variable $X\\sim F_X(x)$ to any other continuous random variable $Z\\sim F_Z(z)$, provided that $F_Z(\\cdot)$ is a one-to-one function,\n",
    "\n",
    "\\begin{align*}\n",
    "    X\\rightarrow F_X(\\cdot)\\xrightarrow{U}F_Z^{-1}(\\cdot)\\rightarrow Z\\tag{17}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red;\"><left>Exercise 4.1</left></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to use i.i.d. $\\text{Uniform}[0, 1]$ random variables to generate a set of i.i.d. exponentially distributed random variables with CDF\n",
    "\n",
    "\\begin{equation}\n",
    "    F_X(x)=(1-e^{-3x})u(x)\\tag{18}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Derive the required transformation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the $\\text{Uniform}[0, 1]$ random variables using the function ```np.random.uniform(0, 1, N)```. Use your `empcdf` function to plot two CDF estimates for the exponentially distributed random variables:  one using a sample size $N = 20$, and one using $N = 200$. Plot these functions in the range `x = np.linspace(-1, 2, 2000)`, and on each plot superimpose the true exponential distribution of equation (18)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Generate samples of X when $N=20$ and $N=200$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:salmon;\"><left>5. Estimating the Probability Density Function</left></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statistical properties of a random variable are completely described by its probability density function (assuming it exists, of course). Therefore, it is oftentimes useful to estimate the PDF, given an observation of a random variable. For example, similar to the empirical CDF, probability density estimates may be used to test a proposed model. They may also be used in non-parametric classification problems, where we need to classify data as belonging to a particular group but without any knowledge of the true underlying class distributions.\n",
    "\n",
    "Notice that we cannot form a density estimate by simply differentiating the empirical CDF, since this function contains discontinuities at the sample locations $X_i$. Rather, we need to estimate the probability that a random variable will fall within a particular interval of the real axis. In this section, we will describe a common method known as the *histogram*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:salmon;\"><left>5.1 The Histogram</left></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to estimate an arbitrary probability density function, $f_X(x)$, within a finite region of the $x$-axis. We will do this by partitioning the region into $L$ equally spaced subintervals, or “bins”, and forming an approximation for $f_X(x)$ within each bin. Let our region of support start at the value $x_0$, and end at $x_L$. Our $L$ subintervals of this region will be $[x_0,x_1],(x_1,x_2],\\dots,(X_{L-1},X_L]$. To simplify our notation we will define *$bin(k)$* to represent the interval $(x_{k−1}, x_k]$, $k = 1,2,\\dots,L$, and define the quantity $\\Delta$ to be the length of each subinterval.\n",
    "\n",
    "\\begin{align*}\n",
    "    bin(k)&=(x_{k-1},x_k]\\quad k=1,2,\\dots,L\\\\\n",
    "    \\Delta&=\\frac{x_L-x_0}{L}\n",
    "\\end{align*}\n",
    "\n",
    "We will also define $\\tilde{f}(k)$ to be the probability that $X$ falls into $bin(k)$.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\tilde{f}(k)&=\\mathbb{P}(X\\in bin(k))\\\\\n",
    "    &=\\int_{x_{k-1}}^{x_k}f_X(x)dx\\tag{19}\\\\\n",
    "    &\\approx f_X(x)\\Delta\\quad\\text{for} x\\in bin(k)\\tag{20}\n",
    "\\end{align*}\n",
    "\n",
    "The approximation in (20) only holds for an appropriately small *bin width* $\\Delta$.\n",
    "\n",
    "Next we introduce the concept of a histogram of a collection of i.i.d. random variables ${X_1,X_2,\\dots,X_N}$. Let us start by defining a function that will indicate whether or not the random variable $X_n$ falls within $bin(k)$.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbb{1}_n(k)=\\begin{cases}1,\\quad&\\text{if }X_n\\in bin(k)\\\\0,\\quad&\\text{if }X_n\\notin bin(k)\\end{cases}\\tag{21}\n",
    "\\end{equation}\n",
    "\n",
    "The *histogram* of $X_n$ at $bin(k)$, denoted as $H(k)$, is simply the number of random variables that fall within $bin(k)$. This can be written as\n",
    "\n",
    "\\begin{equation}\n",
    "    H(k)=\\sum_{n=1}^N\\mathbb{1}_n(k)\\tag{22}\n",
    "\\end{equation}\n",
    "\n",
    "We can show that the *normalized* histogram, $H(k)/N$, is an unbiased estimate of the probability of $X$ falling in $bin(k)$. Let us compute the expected value of the normalized histogram.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbb{E}\\left[\\frac{H(k)}{N}\\right]&=\\frac{1}{N}\\sum_{n=1}^N\\mathbb{E}[\\mathbb{1}_n(k)]\\\\\n",
    "    &=\\frac{1}{N}\\sum_{n=1}^N{1\\cdot\\mathbb{P}(x_n\\in bin(k))+0\\cdot\\mathbb{P}(X_n\\notin bin(k))}\\\\\n",
    "    &=\\tilde{f}(k)\n",
    "\\end{align*}\n",
    "\n",
    "The last equality results from the definition of $\\tilde{f}(k)$, and from the assumption that the $X_n$’s have the same distribution. A similar argument may be used to show that the variance of $H(k)$ is given by\n",
    "\n",
    "\\begin{equation}\n",
    "    \\text{Var}\\left[\\frac{H(k)}{N}\\right]=\\frac{1}{N}\\tilde{f}(k)(1-\\tilde{f}(k))\n",
    "\\end{equation}\n",
    "\n",
    "Therefore, as $N$ grows large, the bin probabilities $\\tilde{f}(k)$ can be approximated by the normalized histogram $H(k)/N$.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\tilde{f}(k)\\approx\\frac{H(k)}{N}\\tag{23}\n",
    "\\end{equation}\n",
    "\n",
    "Using (20), we may then approximate the density function $f_X(x)$ within *$bin(k)$* by\n",
    "\n",
    "\\begin{equation}\n",
    "    f_X(x)\\approx \\frac{H(k)}{N\\Delta}\\quad\\text{for }x\\in bin(k)\\tag{24}\n",
    "\\end{equation}\n",
    "\n",
    "Notice this estimate is a staircase function of $x$ which is constant over each interval *$bin(k)$*. It can also easily be verified that this density estimate integrates to $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red;\"><left>Exercise 5.1</left></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $U$ be a uniformly distributed random variable on the interval $[0, 1]$ with the following cumulative probability distribution, $F_U(u)$:\n",
    "\n",
    "\\begin{equation}\n",
    "    F_U(u)=\\begin{cases}0,\\quad&\\text{if }u<0\\\\u,\\quad&\\text{if } 0\\leq u\\leq 1\\\\1,\\quad&\\text{if }u>1\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "We can calculate the cumulative probability distribution for the new random variable $X=U^{1/3}$.\n",
    "\n",
    "\\begin{align*}\n",
    "    F_X(x)&=\\mathbb{P}(X\\leq x)\\\\\n",
    "    &=\\mathbb{P}(U^{1/3}\\leq x)\\\\\n",
    "    &=\\mathbb{P}(U\\leq x^3)\\\\\n",
    "    &=F_U(u)|_{u=x^3}\\\\\n",
    "    &=\\begin{cases}0,\\quad&\\text{if }x<0\\\\x^3,\\quad&\\text{if }0\\leq x\\leq 1\\\\1,\\quad&\\text{if }x>1\\end{cases}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Plot $F_X(x)$ for $x\\in[0, 1]$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Analytically calculate the probability density $f_X(x)$, and plot it for $x \\in [0, 1]$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Using $L = 20$, $x_0 = 0$ and $x_L = 1$, write code to compute $\\tilde{f}(k)$, the probability of $X$ falling into *$bin(k)$*. Plot $\\tilde{f}(k)$ for $k=1,\\dots,L$ using the ```plt.stem()``` function.**\n",
    "\n",
    "**Hint:** Use the fact that $\\tilde{f}(k) = F_X(x_k) − F_X(x_{k−1})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Show (mathematically) how $f_X(x)$ and $\\tilde{f}(k)$ are related.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Generate $1000$ samples of a random variable $U$ that is uniformly distributed between $0$ and 1 (using the ```np.random.uniform(0, 1, 1000)```). Then form the random vector $X$ by computing $X=U^{1/3}$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Use the Python function [```np.histogram()```](https://numpy.org/doc/stable/reference/generated/numpy.histogram.html) to plot a *normalized* histogram for your samples of $X$, using $20$ bins uniformly spaced on the interval $[0, 1]$. Use the ```plt.stem()``` command to plot the normalized histogram $H(k)/N$.**\n",
    "\n",
    "**Hint:** Use the Python command ```H, _ = np.histogram(X, bins=20, range=(0, 1))``` to obtain the normalized histogram. The underscore `_` means that whatever the second argument the function returns, I don't care and don't bother assigning it to a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. How do these plots ($H(k)/N$ and $\\tilde{f}(k)$) compare?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Discuss the tradeoffs (advantages and the disadvantages) between selecting a very large or very small bin-width.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insert your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
